{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section E: Multiclass Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are asked to demonstrate your understanding of linear models for classification. You expand the binary-class perceptron algorithm that is covered in Activity 1 of Module 3 into a multiclass classifier.\n",
    "\n",
    "Like most other techniques for training linear classifiers, the perceptron generalizes naturally to multiclass classification.  Here, the input x and the output y are drawn from arbitrary sets. A feature representation function f(x,y) maps each possible input/output pair to a finite-dimensional real-valued feature vector. The feature vector is multiplied by a weight vector w, the resulting score is used to choose among many possible outputs. Learning again iterates over the examples, predicting an output for each, leaving the weights unchanged when the predicted output matches the target, and changing them when it does not. The update becomes: $w{t+1}=w{t}+f(x,y)-tn.$\n",
    "\n",
    "This multiclass feedback formulation reduces to the original perceptron when x is a real-valued vector, y is chosen from {0,1}, and f(x,y)=yx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 :Multiclass Perceptron\n",
    "> ##### 1. Loading the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading traning data in Task1_train_dataframe\n",
    "train_data = read.csv(\"Task1D_train.csv\")\n",
    "# Loading test data in Task1A_test_dataframe\n",
    "test_data = read.csv(\"Task1D_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### 2. Implement the multiclass perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the train data\n",
    "train.len <- nrow(train_data)\n",
    "# Length of the test data\n",
    "test.len <- nrow(test_data)\n",
    "# Training data from train_data\n",
    "train.data <- train_data[,-5]\n",
    "#Testing data from test_data\n",
    "test.data <- test_data[,-5] \n",
    "# Training label from train_data\n",
    "train.label <- train_data[,5]\n",
    "# Testing label from test_data\n",
    "test.label <- test_data[,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basis function \n",
    "Phi <- as.matrix(cbind(1, train.data)) # add a column of 1 as phi_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Error function\n",
    "> Arguments\n",
    ">1. train.len :- train data length\n",
    ">2. weights :- data frame of different weights for classification\n",
    ">3. classes :- vector of classes\n",
    ">4. train.label :- train label\n",
    "\n",
    "It returns the percentage of missclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "error <- function(train.len,weights,Phi,classes,train.label){\n",
    "    # Variable to keep count of misclassification\n",
    "    mis_class = 0\n",
    "    for (i in 1:train.len){\n",
    "        # Getting the index number of the argument which has the maximum value\n",
    "        c_ind = data.frame(sort(c(Phi[i,]%*%weights[,1],Phi[i,]%*%weights[,2],Phi[i,]%*%weights[,3]),\n",
    "                                  index.return = TRUE))[3,2]\n",
    "        # Checking if predicted class and original label are same.\n",
    "        if (classes[c_ind]!=train.label[i]){\n",
    "            # If label is different then increamenting the count of the variable.\n",
    "            mis_class = mis_class + 1\n",
    "        }\n",
    "    }\n",
    "    return (mis_class/train.len*100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "eta <- 0.01 # Learning rate\n",
    "epsilon <- 0.001 # Stoping criterion\n",
    "\n",
    "tau <- 1 # iteration counter\n",
    "tau.max <- 100 # Maximum number of iterations\n",
    "\n",
    "\n",
    "W1 <- matrix(,nrow=tau.max, ncol=ncol(Phi)) # Empty Weight vector for class c1\n",
    "W1[1,] <- runif(ncol(Phi)) # Random initial values for weight vector W1\n",
    "\n",
    "W2 <- matrix(,nrow=tau.max, ncol=ncol(Phi)) # Empty Weight vector For class c2\n",
    "W2[1,] <- runif(ncol(Phi)) # Random initial values for weight vector W2\n",
    "\n",
    "W3 <- matrix(,nrow=tau.max, ncol=ncol(Phi)) # Empty Weight vector for class W3\n",
    "W3[1,] <- runif(ncol(Phi)) # Random initial values for weight vector W3\n",
    "\n",
    "# Vector of different classes from data set  \n",
    "classes <- as.character(unique(unlist(test_data[\"y\"])))\n",
    "# Creating a data frame to have all the weights in it\n",
    "weights <- data.frame(W1=W1[tau,],W2=W2[tau,],W3=W3[tau,])\n",
    "\n",
    "error.trace <- matrix(0,nrow=tau.max, ncol=1) # Placeholder for errors\n",
    "\n",
    "error.trace[1] <- error(train.len,weights,Phi,classes,train.label) # record error for initial weights\n",
    " \n",
    "terminate <- FALSE # termination status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We learn the model parameter using SGD below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "while(!terminate){\n",
    "    # resuffling train data and associated labels:\n",
    "    train.index <- sample(1:train.len, replace = FALSE)\n",
    "    Phi <- Phi[train.index,]\n",
    "    T <- train.label[train.index]\n",
    "    \n",
    "    for (i in 1:train.len){\n",
    "        if (tau == tau.max) {break}\n",
    "        # Getting the index number of the argument which has the maximum value\n",
    "        c_ind = data.frame(sort(c(Phi[i,]%*%weights[,1],Phi[i,]%*%weights[,2],Phi[i,]%*%weights[,3]),\n",
    "                                  index.return = TRUE))[3,2]\n",
    "        \n",
    "        # look for missclassified samples\n",
    "        if (classes[c_ind]!=T[i]){\n",
    "            \n",
    "            weights[,c_ind] <- weights[,c_ind] - eta * Phi[i,] \n",
    "            \n",
    "            # Finding the index number of original class label from classes vector \n",
    "            original_c_indx = match(T[i],classes)\n",
    "            # updating the values of corresponding column in weights dataframe to have the latest value of weight.\n",
    "            weights[,original_c_indx] <- weights[,original_c_indx] + eta * Phi[i,]\n",
    "            \n",
    "            # update tau counter\n",
    "            tau <- tau +1\n",
    "            \n",
    "            # update the weights\n",
    "            W1[tau,] <- weights[,1];W2[tau,] <- weights[,2];W3[tau,] <- weights[,3]\n",
    "            \n",
    "            # update the record of error\n",
    "            error.trace[tau] <- error(train.len,weights,Phi,classes,T)\n",
    "        } \n",
    "        \n",
    "    }\n",
    "    \n",
    "    # decrease eta:\n",
    "    eta = eta * 0.99\n",
    "    # recalculate termination conditions\n",
    "    terminate <- tau >= tau.max | \n",
    "        abs(error.trace[tau]-error.trace[tau-1]) <= epsilon \n",
    "    \n",
    "    \n",
    "}\n",
    "# cut the empty part of the matrix (when the loop stops before tau == tau.max)\n",
    "W1 <- W1[1:tau,];W2 <- W2[1:tau,];W2 <- W2[1:tau,] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### 3. Multiclass Perceptron with Neta= 0.09 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basis function \n",
    "test_phi <- as.matrix(cbind(1, test.data)) # add a column of 1 as phi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "eta <- 0.09 # Learning rate\n",
    "epsilon <- 0.001 # Stoping criterion\n",
    "\n",
    "tau <- 1 # iteration counter\n",
    "tau.max <- 100 # Maximum number of iterations\n",
    "\n",
    "\n",
    "W1 <- matrix(,nrow=tau.max, ncol=ncol(Phi)) # Empty Weight vector for class c1\n",
    "W1[1,] <- runif(ncol(Phi)) # Random initial values for weight vector W1\n",
    "\n",
    "W2 <- matrix(,nrow=tau.max, ncol=ncol(Phi)) # Empty Weight vector For class c2\n",
    "W2[1,] <- runif(ncol(Phi)) # Random initial values for weight vector W2\n",
    "\n",
    "W3 <- matrix(,nrow=tau.max, ncol=ncol(Phi)) # Empty Weight vector for class W3\n",
    "W3[1,] <- runif(ncol(Phi)) # Random initial values for weight vector W3\n",
    "\n",
    "# Vector of different classes from data set  \n",
    "classes <- as.character(unique(unlist(test_data[\"y\"])))\n",
    "# Creating a data frame to have all the weights in it\n",
    "weights <- data.frame(W1=W1[tau,],W2=W2[tau,],W3=W3[tau,])\n",
    "\n",
    "error.trace <- matrix(0,nrow=tau.max, ncol=1) # Placeholder for errors\n",
    "\n",
    "error.trace[1] <- error(train.len,weights,Phi,classes,train.label) # record error for initial weights\n",
    " \n",
    "terminate <- FALSE # termination status\n",
    "\n",
    "# Total length of the mini_batch error\n",
    "total.batch <- train.len%/%5\n",
    "# Data frame to hole the mini batch number and corresponding error\n",
    "mini_batch_error <- data.frame(\"Number\"=1:total.batch,\"error\"=rep(0,total.batch))\n",
    "# Variable for updating error after processing every 5 training data points\n",
    "count <- 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "while(!terminate){\n",
    "    # resuffling train data and associated labels:\n",
    "    train.index <- sample(1:train.len, replace = FALSE)\n",
    "    Phi <- Phi[train.index,]\n",
    "    T <- train.label[train.index]\n",
    "    \n",
    "    for (i in 1:train.len){\n",
    "        if (tau == tau.max) {break}\n",
    "        # Getting the index number of the argument which has the maximum value\n",
    "        c_ind = data.frame(sort(c(Phi[i,]%*%weights[,1],Phi[i,]%*%weights[,2],Phi[i,]%*%weights[,3]),\n",
    "                                  index.return = TRUE))[3,2]\n",
    "        \n",
    "        # look for missclassified samples\n",
    "        if (classes[c_ind]!=T[i]){\n",
    "            \n",
    "            weights[,c_ind] <- weights[,c_ind] - eta * Phi[i,] \n",
    "            \n",
    "            # Finding the index number of original class label from classes vector \n",
    "            original_c_indx = match(T[i],classes)\n",
    "            # updating the values of corresponding column in weights dataframe to have the latest value of weight.\n",
    "            weights[,original_c_indx] <- weights[,original_c_indx] + eta * Phi[i,]\n",
    "            \n",
    "            # update tau counter\n",
    "            tau <- tau +1\n",
    "            \n",
    "            # update the weights\n",
    "            W1[tau,] <- weights[,1];W2[tau,] <- weights[,2];W3[tau,] <- weights[,3]\n",
    "            \n",
    "            # update the record of error\n",
    "            error.trace[tau] <- error(train.len,weights,Phi,classes,T)\n",
    "        }\n",
    "        \n",
    "        if(i%%5 == 0 ){\n",
    "            mini_batch_error[count,2] <- error(test.len,weights,test_phi,classes,test.label)\n",
    "            count <- count+1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # decrease eta:\n",
    "    eta = eta * 0.99\n",
    "    # recalculate termination conditions\n",
    "    terminate <- tau >= tau.max | \n",
    "        abs(error.trace[tau]-error.trace[tau-1]) <= epsilon \n",
    "    \n",
    "    \n",
    "}\n",
    "# cut the empty part of the matrix (when the loop stops before tau == tau.max)\n",
    "W1 <- W1[1:tau,];W2 <- W2[1:tau,];W2 <- W2[1:tau,] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### Plotting test error vs Number of Mini Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\n6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "ggplot(mini_batch_error,aes(x=Number,y=error))+geom_line(color=\"blue\") +\n",
    "geom_line() + ggtitle('Test error vs Mini Batches') + theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When tried running the code number of times, the batch number giving the minimum test varies, hence we cannot say anything very confirm about the optimal batch number.\n",
    "> But when run once, we can conclude the optimal batch number which gives the least test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
